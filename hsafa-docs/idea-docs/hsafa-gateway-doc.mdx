---
title: Distributed Agent Platform Architecture
description: Building an Agent Builder + Distributed Agent Runtime (gateway) that scales into an agentic network (SmartSpaces + Entities) with persistent memory and distributed tool execution.
---

# üß† The Big Idea

You are building an **Agent Builder + Distributed Agent Runtime** that can grow into an **agentic system network**.

A system where:

* Users **create agents** via config
* Agents run **on your server** (the gateway is the runtime)
* Any client (web, mobile, node app) can:
  * Start a run
  * Watch it stream
  * Refresh and reconnect
* Agents can call **tools that run anywhere** (server, browser, other devices)

This is like giving AI agents a **backend, memory, and a network of devices**.

The update: instead of thinking only in ‚Äúone agent ‚Üî one chat‚Äù, the platform‚Äôs native model becomes **many Entities collaborating inside shared contexts** (SmartSpaces).

---

# üï∏Ô∏è Agentic Network Model (SmartSpaces + Entities)

## Core primitives

### SmartSpace

A **SmartSpace** is a shared context space (a timeline of events/messages) where participants collaborate.

- A SmartSpace can contain any number of participants.
- SmartSpaces can be public (many participants) or private (small, scoped contexts like ‚ÄúManager SmartSpace‚Äù).

### Entity

An **Entity** is a participant in the system. There are exactly two types:

- **Human Entity** (a user from your app)
- **Agent Entity** (an AI agent)

External services (Jira, Slack, IoT devices, payment gateways, cron jobs, Node.js backends) are **NOT entities**. They are **services** ‚Äî they trigger agents via API (`POST /api/agents/{agentId}/trigger`) and submit tool results, but have no space membership or identity in the system.

An Agent Entity can belong to multiple SmartSpaces.

### Client

A **Client** is a connection point where streams are delivered and responses are received.

- Examples: web browser, mobile app, Node.js backend, IoT device
- A Client is **not** an Entity ‚Äî it is a delivery channel

One Entity can connect from **multiple Clients** simultaneously. For example, a single Human Entity (user) might be logged in on both web and mobile at the same time. Both Clients receive the same stream; both can send messages as that Entity.

### Run (Agent execution)

A **Run** is a general-purpose execution of **one Agent Entity**. Runs are **not tied to any space** ‚Äî the agent interacts with spaces through tools (`sendSpaceMessage`, `readSpaceMessages`).

- A human message in a space triggers a run for the **admin agent** of that space
- An agent message with a `mention` triggers a run for the mentioned agent
- External services trigger runs directly via API (`POST /api/agents/{agentId}/trigger`)
- Scheduled plans trigger runs automatically
- The agent's LLM text output is internal (reasoning/planning). All visible communication happens through `sendSpaceMessage`.

### Step (inside a Run)

Inside a Run, execution is a multi-step reasoning-and-acting loop:

- **Run** = a complete multi-step AI interaction
- **Step** = a single LLM call within that Run

This distinction matters because the gateway streams **partial outputs** (text deltas, tool calls, tool results) while the Run is still in progress.

## Triggers (what starts a Run)

There are exactly three trigger types:

* **`space_message`** ‚Äî A human (or agent via `mention`) posted a message in a space
* **`plan`** ‚Äî The agent's own scheduled plan triggered it
* **`service`** ‚Äî An external service triggered the agent directly via API (`POST /api/agents/{agentId}/trigger`)

## Scheduling and long-term behavior

Each Agent Entity maintains:

* **Plan**: schedules future executions (cron-like). Example: ‚Äúsend a reminder at 6 PM‚Äù.
* **Goals**: short-term and long-term objectives that influence decisions over time.

The key design choice: **Plans and Goals are first-class state**, not just prompt text.

---

<details>
<summary>Architecture (later)</summary>

# üèóÔ∏è System Architecture

## 1Ô∏è‚É£ Agent Builder (Control Plane)

Users send agent configs:

```json
{
  "version": "1.0",
  "agent": {
    "name": "research-agent",
    "system": "..."
  },
  "model": {
    "provider": "openai",
    "name": "gpt-4.1-mini"
  },
  "tools": []
}
```

You:

* Store config in **durable storage**
* Reuse config when runs start

---

## 2Ô∏è‚É£ Agent Runtime (Execution Plane)

When a user starts a run:

1. Load agent config
2. Load chat history
3. Start the agent engine (the reasoning + tool loop)
4. Stream output
5. Handle tool calls
6. Save everything

Your system is the **body + memory + network**.

In the SmartSpace model, the gateway runtime expands slightly:

1. A message/event is written to a SmartSpace timeline.
2. The gateway triggers Runs for Agent Entities that belong to that SmartSpace.
3. Each Run streams events (text/tool-calls/tool-results) and may append new messages/events back into the SmartSpace.

---

</details>

# üîÅ Example scenario: Leave Request (Cross-SmartSpace)

A Human Entity asks an Agent Entity (in the Employee SmartSpace) to send a leave request to their manager.

1. The Human posts a message in the **Employee SmartSpace**.
2. The **admin agent** of the space is triggered with a general-purpose run.
3. The Agent calls `sendSpaceMessage(managerSpace, "Sarah is requesting 2 days PTO next week. Approve?", wait: { for: [{ type: "human" }] })` ‚Äî the message streams into the Manager SmartSpace and the tool blocks until the manager replies.
4. The Manager sees the message and replies "Approved."
5. The Agent's `wait` resolves with the manager's reply.
6. The Agent calls `sendSpaceMessage(employeeSpace, "Your leave request was approved!")` ‚Äî streams back to the employee.

All of this happens in **one general-purpose run**. No child runs, no goToSpace. The agent uses `sendSpaceMessage` with `wait` for cross-space request-response.

While waiting, if the employee asks for status, a **new run** is created. The agent can call `getMyRuns` to see it already has a run waiting on the manager's reply, and respond accordingly.

---

# üß∞ Tool Visibility and Interaction

## Tool call visibility modes

When an Agent calls a tool, it can decide **who can see and interact with that tool call**:

### 1. Additional tools

The Agent can mark a tool call as visible to **all Entities** in the SmartSpace. This allows:

- Entities to see the tool call and its parameters
- Entities to provide a response (output) to the tool
- Collaborative workflows where multiple participants interact with the same tool execution

**Use case**: A form tool that a specific user needs to fill out, or a confirmation tool that requires approval.

### 2. Prebuilt tools (internal)

**Prebuilt tools** are internal tools that **no Entity should see or interact with**. These are the Agent's private capabilities for managing its own state and reasoning.

---

# üé® Tool Display Configuration (Client-Side)

> **Note:** Tool display configuration is handled entirely by the **client SDK**, not the gateway or database. The gateway streams all tool events; the client decides what to show.

## Architecture

**Gateway streams all tool events:**
- `tool-input-start`, `tool-input-delta`, `tool-input-available`, `tool-output-available`
- Includes tool metadata (name, arguments, result)

**Client SDK decides display:**
- Which tools to show/hide
- Whether to show input/output
- Custom UI components per tool

## Display Modes

Each tool can be configured with a `display` property in the **agent config** (interpreted by the client):

```json
{
  "name": "searchDatabase",
  "display": {
    "mode": "full" | "minimal" | "hidden",
    "showInput": true,
    "showOutput": true
  }
}
```

### Display Mode Options

| Mode | Description |
| ---- | ----------- |
| `full` | Show tool call with input and output (based on `showInput`/`showOutput` flags) |
| `minimal` | Only show that the tool was called (name + status indicator, no input/output) |
| `hidden` | Tool call is not shown in the chat UI at all |

### Configuration Examples

```json
// Full display - show everything
{
  "name": "webSearch",
  "display": { "mode": "full", "showInput": true, "showOutput": true }
}

// Show input only (e.g., search query shown, results hidden)
{
  "name": "internalLookup",
  "display": { "mode": "full", "showInput": true, "showOutput": false }
}

// Minimal - only show that tool was called
{
  "name": "updateMemory",
  "display": { "mode": "minimal" }
}

// Hidden - internal tool, never shown
{
  "name": "planManagement",
  "display": { "mode": "hidden" }
}
```

### Default Behavior (Client SDK)

The client SDK applies these defaults when no explicit display config is provided:

- **Additional tools**: Default to `{ mode: "full", showInput: true, showOutput: true }`
- **Prebuilt tools (internal)**: Default to `{ mode: "hidden" }`

### Permission-Based Visibility

The system uses **secret key** (`sk_...`) for admin access and **public key** (`pk_...`) for regular access. Both are system-wide (env vars, not per-space). The client SDK uses this to control prebuilt tool visibility:

| Permission Level | Prebuilt Tools Display |
|-----------------|------------------------|
| **Admin** (secret key via `x-secret-key` header) | `full` - see tool name, input, and output |
| **Regular** (public key via `x-public-key` + JWT) | `minimal` - see "tool called" indicator only, no input/output |

This ensures:
- **Security**: Sensitive internal tool data hidden from regular users
- **Transparency**: Admins can debug and audit full agent behavior
- **Clean UX**: Regular users see simple progress indicators without noise

---

# üß© Custom Tool UI Components (TODO)

> **Note:** This section describes planned functionality that has not been implemented yet.

Tools can have custom UI components that replace the default tool display. This enables rich, interactive experiences.

## Architecture

The Hsafa stack uses:
- **`@hsafa/react`** ‚Äî Hooks-only SDK for data fetching (`useMessages`, `useHsafaClient`, etc.)
- **`@assistant-ui/react`** ‚Äî UI primitives (`MessagePrimitive`, `ThreadPrimitive`, etc.)

Custom tool UIs are registered via `MessagePrimitive.Content` components.

## Registering Custom Tool UIs

### Option 1: Tools() API with Toolkit (Recommended)

The recommended approach is to define tools with their `render` function in a toolkit:

```tsx
import { useAui, Tools, type Toolkit } from "@assistant-ui/react";

const toolkit: Toolkit = {
  webSearch: {
    description: "Search the web",
    parameters: z.object({ query: z.string() }),
    // No execute - tool runs on gateway
    render: ({ args, result, status }) => (
      <SearchResultsCard
        query={args.query}
        results={result?.results}
        loading={status.type === "running"}
      />
    ),
  },
  
  requestApproval: {
    description: "Request user approval",
    parameters: z.object({ title: z.string(), amount: z.number() }),
    // No execute - basic tool, response via addResult
    render: ({ args, result, status, addResult }) => {
      if (result) return <div>{result.approved ? "‚úÖ Approved" : "‚ùå Rejected"}</div>;
      return (
        <div className="rounded border p-4">
          <p>{args.title}: ${args.amount}</p>
          <button onClick={() => addResult({ approved: true })}>Approve</button>
          <button onClick={() => addResult({ approved: false })}>Reject</button>
        </div>
      );
    },
  },
};

// Register in runtime provider
function MyRuntimeProvider({ children }) {
  const runtime = useHsafaRuntime({ /* ... */ });

  const aui = useAui({
    tools: Tools({ toolkit }),
  });

  return (
    <AssistantRuntimeProvider aui={aui} runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

### Option 2: Per-Tool Components via MessagePrimitive.Content

For simpler setups or when using `useExternalStoreRuntime`, pass tool components directly:

```tsx
import { MessagePrimitive } from "@assistant-ui/react";

// Custom UI components for specific tools
const toolComponents = {
  webSearch: WebSearchToolUI,
  requestApproval: ApprovalToolUI,
};

function AssistantMessage() {
  return (
    <MessagePrimitive.Root>
      <MessagePrimitive.Content
        components={{
          tools: {
            ...toolComponents,
            Fallback: DefaultToolUI, // fallback for unregistered tools
          },
        }}
      />
    </MessagePrimitive.Root>
  );
}
```

This is what the `nextjs-test-app` currently uses with `useExternalStoreRuntime`.

## Tool UI Component Props

All tool UI components receive:

```tsx
interface ToolUIProps {
  toolName: string;
  toolCallId: string;
  args: Record<string, unknown>;
  argsText: string;                    // JSON stringified args
  result?: unknown;
  status: {
    type: "running" | "complete" | "incomplete" | "requires-action";
    reason?: string;                   // e.g., "error", "cancelled"
  };
  
  // For interactive tools - submit a result back to the gateway
  addResult?: (result: unknown) => void;
}
```

## Custom UI for Basic Tools

For **basic tools** (see [basic-tool.md](/hsafa-tools/basic-tool.md)), custom UIs can return a tool response via `addResult()`:

```tsx
function ApprovalToolUI({ args, result, status, addResult }: ToolUIProps) {
  // Already completed
  if (result) {
    return <div>{result.approved ? "‚úÖ Approved" : "‚ùå Rejected"}</div>;
  }

  // Waiting for user input
  return (
    <div className="rounded border p-4">
      <p>{args.title}</p>
      <div className="flex gap-2 mt-3">
        <button onClick={() => addResult({ approved: true })}>Approve</button>
        <button onClick={() => addResult({ approved: false })}>Reject</button>
      </div>
    </div>
  );
}
```

## Custom UI for Gateway-Executed Tools

Tools that execute on the gateway can still have custom visualization:

```tsx
function DatabaseQueryToolUI({ args, result, status }: ToolUIProps) {
  if (status.type === "running") {
    return <QueryLoadingState query={args.sql} />;
  }
  
  if (status.type === "incomplete" && status.reason === "error") {
    return <ErrorDisplay message="Query failed" />;
  }

  return <DataTable rows={result.rows} columns={result.columns} />;
}
```

## Display Mode + Custom UI Integration

The `display` configuration works with custom UIs:

```json
{
  "name": "webSearch",
  "display": { "mode": "full", "showInput": true, "showOutput": true }
}
```

- If `display.mode` is `"hidden"`, the tool UI is not rendered at all
- If `display.mode` is `"minimal"`, the custom UI receives a hint to render minimally
- If `display.mode` is `"full"`, the custom UI renders fully

The custom UI can check `display` config via props and adjust rendering accordingly.

## Fallback Behavior

If no custom UI is registered for a tool:
1. Check the tool's `display` configuration
2. Render using the default `ToolFallback` component (collapsible with args/result)

```tsx
// Default fallback shows tool name, status, and expandable args/result
function DefaultToolUI({ toolName, args, status }: ToolUIProps) {
  const isRunning = status.type === "running";
  return (
    <div className="flex items-center gap-2 rounded border px-2 py-1 text-xs">
      {isRunning ? <LoaderIcon className="animate-spin" /> : <CheckIcon />}
      <span>{isRunning ? "Running" : "Completed"} {toolName}</span>
    </div>
  );
}
```

---

# üß∞ Prebuilt tools every Agent Entity should have

These are internal tools that Entities do not see or interact with:

1. **Plan management tools**

   * Update its schedule (Plan)
   * Read its scheduled actions

2. **Goal management tools**

   * Update its Goals
   * Read its Goals

3. **Memory tools**

   * Store long-term facts, user preferences, learnings
   * Retrieve memories by topic or Entity
   * Memory persists across Runs and SmartSpaces

4. **SmartSpace awareness tools**

   * Read the list of SmartSpaces it belongs to
   * Read messages/events from a specific SmartSpace

5. **Entity awareness tools**

   * List Entities in a SmartSpace
   * Look up Entity info (who is this person, what are their preferences)

6. **Space communication tools**

   * `sendSpaceMessage` ‚Äî send a message to any space (with optional `mention` to trigger another agent, optional `wait` to block for a reply)
   * `readSpaceMessages` ‚Äî read recent messages from any space
   * `delegateToAgent` ‚Äî (admin only) silently hand off to another agent
   * `getMyRuns` ‚Äî see own concurrent active runs

7. **SmartSpace management tools**

   * Create SmartSpaces
   * Delete SmartSpaces

8. **Time awareness tools**

   * Get current time
   * Understand how long ago events happened
   * Reason about deadlines and urgency

9. **Self-reflection tools**

   * Read its own past Runs
   * Summarize what it learned or did wrong
   * Track patterns in its behavior
