---
title: Distributed Agent Platform Architecture
description: Building an Agent Builder + Distributed Agent Runtime with persistent memory and distributed tool execution.
---

# ğŸ§  The Big Idea

You are building an **Agent Builder + Distributed Agent Runtime**

A system where:

* Users **create agents** via config
* Agents run **on your server**
* Any client (web, mobile, node app) can:
  * Start a run
  * Watch it stream
  * Refresh and reconnect
* Agents can call **tools that run anywhere** (server, browser, other devices)

This is like giving AI agents a **backend, memory, and a network of devices**.

---

# ğŸ—ï¸ System Architecture

## 1ï¸âƒ£ Agent Builder (Control Plane)

Users send agent configs:

```json
{
  "name": "research-agent",
  "model": "gpt-5",
  "systemPrompt": "...",
  "tools": [...]
}
```

You:

* Store config in **PostgreSQL**
* Cache hot agents in **Redis or memory**
* Reuse config when runs start

---

## 2ï¸âƒ£ Agent Runtime (Execution Plane)

When a user starts a run:

1. Load agent config
2. Load chat history
3. Start the agent using **Vercel AI SDK Core**
4. Stream output
5. Handle tool calls
6. Save everything

The SDK is only the **brain**.
Your system is the **body + memory + network**.

---

# ğŸ’¾ Storage Layers

## ğŸ—„ PostgreSQL (Permanent Memory)

Stores long-term data:

### Tables

**agents**

* id
* config_json

**runs**

* id
* agent_id
* status (running / waiting_tool / done)

**messages**

* id
* run_id
* role (user/assistant/tool)
* content
* type (chunk/final/tool_call/tool_result)

This lets any client reload full history.

---

## âš¡ Redis (Live Memory)

Used for **realtime + streaming state**

### Redis Streams

Key per run:

```
run:{runId}:stream
```

Stores:

* text chunks
* tool call events
* tool results
* status updates

This allows:
âœ… Resume after refresh
âœ… Multiple clients watching same run
âœ… No lost streaming data

---

# ğŸŒŠ Streaming Flow

### Agent â†’ Redis

While model streams:

```
XADD run:123:stream chunk "Hello"
XADD run:123:stream chunk " world"
```

### Client â†’ Server (SSE)

Client subscribes:

```
GET /runs/123/stream
```

Server reads Redis stream and pushes events.

If page refreshes:

* Client reconnects
* Server continues from last event ID
* Stream resumes seamlessly

---

# ğŸ›  Tool System (Distributed Execution)

This is the powerful part.

Agents can call tools that run:

| Location    | Example                  |
| ----------- | ------------------------ |
| Server      | DB queries, APIs         |
| Browser     | Local files, camera      |
| Node client | Company internal systems |

---

## ğŸ”„ Tool Call Lifecycle

### 1ï¸âƒ£ Agent requests tool

SDK emits a tool call â†’ you intercept

You store event and publish:

```json
{
  "type": "tool_call",
  "callId": "abc123",
  "tool": "scanFiles",
  "args": {...},
  "targetClient": "deviceA"
}
```

Saved in:

* PostgreSQL (history)
* Redis Stream (live)
* Redis PubSub (notify device)

---

### 2ï¸âƒ£ Target Client Executes Tool

Client connected via WebSocket receives the request, runs the tool locally, and sends back:

```json
{
  "type": "tool_result",
  "callId": "abc123",
  "result": {...}
}
```

---

### 3ï¸âƒ£ Server Resumes Agent

You feed result back into the model:

```
assistant â† tool result
```

Agent continues streaming as if nothing happened.

All watchers see this live via Redis stream.

---

# ğŸ§  Role of Vercel AI SDK (Core Only)

You DO NOT use:
âŒ `useChat` 
âŒ AI SDK UI helpers

You ONLY use:

| Function             | Purpose                                |
| -------------------- | -------------------------------------- |
| `streamText`         | Stream model output                    |
| Tool calling support | Let model decide when tools are needed |

You handle:

* Tool execution
* Message storage
* Streaming infra
* Run lifecycle

SDK = **decision engine only**

---

# ğŸ”Œ Client Types Supported

Because everything goes through your API:

| Client           | Works? | How              |
| ---------------- | ------ | ---------------- |
| Vite / React     | âœ…      | SSE + WebSockets |
| Mobile app       | âœ…      | HTTP + WS        |
| Node app         | âœ…      | HTTP + WS        |
| Multiple devices | âœ…      | Shared runId     |

---

# ğŸ§­ Run Lifecycle

Each run moves through states:

```
queued â†’ running â†’ waiting_tool â†’ running â†’ completed
```

Stored in DB so system can recover if server restarts.

---

# ğŸ§° Final Tool Stack

| Purpose          | Technology                |
| ---------------- | ------------------------- |
| AI Agent Brain   | **Vercel AI SDK (Core)**  |
| API Server       | Node.js (Fastify/Express) |
| Database         | PostgreSQL                |
| ORM              | Prisma or Drizzle         |
| Live Streaming   | **Redis Streams**         |
| Tool Messaging   | **Redis Pub/Sub**         |
| Client Streaming | SSE                       |
| Device Tool Link | WebSockets                |

---

# ğŸ What You're Building (In One Sentence)

You're building a **distributed, persistent, multi-device AI agent runtime** where agents have memory, can stream across sessions, and can use tools running anywhere.

That's startup-level infrastructure, not just an app ğŸ’ª
